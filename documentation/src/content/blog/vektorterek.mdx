---
title: 'BevezetÃ©s a vektorterekbe'
description: 'A vektorterek axiomatikus felÃ©pÃ­tÃ©se, lineÃ¡ris kombinÃ¡ciÃ³, fÃ¼ggetlensÃ©g Ã©s bÃ¡zis.'
pubDate: 'Jan 02, 2026'
heroImage: '../../assets/sponge.png'
tags: ['math', 'linear-algebra', 'vectors']
---

import Question from '../../components/Question.astro';
import ProofBox from '../../components/ProofBox.astro';
import AxiomBox from '../../components/AxiomBox.astro';

## Vektorterek

ğŸ‘¨â€ğŸ«: Elerkeztunk egy ujabb fontos reszhez. Mit tanultatok a kozepiskolaban a vektorokrol?

ğŸ™‹â€â™‚ï¸: Hat a vektor az ilyen nyilacska a sikon vagy a terben. De kicsit formalisabban olyasmit mondtunk hogy egy iranyitott szakasz, vagy tombbe rendezett szamok.

ğŸ‘¨â€ğŸ«: Igen, igen valoban lehet igy reprezentalni az $\mathbb{R}^{2}$-ben vagy $\mathbb{R}^{3}$-ban lako vektorokat. Emellett matematikusok megalkottak egy szabalyrendszert ami kiszelesiti a vektorok fogalmat. Gondolhatsz ugy is a dologra hogy megfigyeljuk hogy a terben lako nyilacskakra milyen szabalyok igazak, osszegyujtjuk ezeket a szabalyokat, es azok a dolgoka mikre ezek a szabalyok igazak azokat vektornak fogjuk hivni. Vagyis pontosabban azt a halmazt amire igazak ezek a szabalyok azt vektorternek, a halmaz egy elemet pedig vektornak. Van otleted hogy milyen szabalyokbol alkotjak a vektorter axiomait?

ğŸ™‹â€â™‚ï¸: Gondolom ossze kell tudjunk adni a vektorokat. Az is jo lenne ha tudnank oket megnyujtani, tehat skalarral szorozni. Meg amugy tudtunk szorozni is vektorokat a "rendes" terben.

ğŸ‘¨â€ğŸ«: Ezek igen jo gondolatok. Kettot kapasbol bele is rakunk a vektorter axiomaiba. Egyet viszont ki fogunk hagyni. 

<Question
  question="Szerinted melyik szabalyt hagyjuk ki a vektorterek axiomai kozul?"
  options={[
    "vektorok osszeadasa",
    "vektorok megnyujtasa (skalarral valo szorzas)",
    "ket vektor osszeszorzasa"
  ]}
  correctAnswerIndex={2}
/>

{/* todo le kell irni mi a test es mi a csopi */}



<AxiomBox title="VektortÃ©r AxiÃ³mÃ¡k">

Legyen egy $K$ test (Ã¡ltalÃ¡ban $\mathbb{R}$ vagy $\mathbb{C}$). Azt mondhatjuk, hogy $V$ egy vektortÃ©r $K$ felett, ha: (az alÃ¡bbiakban $u,v,w\in V$ Ã©s $\lambda,\mu\in K$)

**Ã–sszeadÃ¡s**

Legyen
$$
+ : V\times V \to V,\qquad (u,v)\mapsto u+v.
$$
A kÃ¶vetkezÅ‘ tulajdonsÃ¡gok teljesÃ¼lnek:
$$
\begin{aligned}
1. \quad & u+(v+w)=(u+v)+w && (\text{asszociatÃ­v}) \\
2. \quad & u+v=v+u && (\text{kommutatÃ­v}) \\
3. \quad & \exists\,0\in V \text{ olyan, hogy } 0+v=v \quad \forall v\in V \text{ esetÃ©n} && (\text{nullvektor}) \\
4. \quad & \forall v\in V\text{-hez } \exists -v\in V \text{ Ãºgy, hogy } v+(-v)=0 && (\text{ellenkezÅ‘ elem})
\end{aligned}
$$

**SkalÃ¡rral valÃ³ szorzÃ¡s**

Legyen
$$
\cdot : K\times V \to V,\qquad (\lambda,v)\mapsto \lambda v.
$$
A kÃ¶vetkezÅ‘ axiÃ³mÃ¡k teljesÃ¼lnek:
$$
\begin{aligned}
1. \quad & \lambda(\mu v)=(\lambda\mu)v && (\text{ez nem pont asszociativitÃ¡s de hasonlÃ³}) \\
2. \quad & \exists\,1\in K \text{ Ãºgy, hogy } 1\cdot v = v \quad \forall v\in V \text{ esetÃ©n} && \\
3. \quad & (\lambda+\mu)v=\lambda v + \mu v && (\text{disztributivitÃ¡s a skalÃ¡rok Ã¶sszeadÃ¡sÃ¡ra}) \\
4. \quad & \lambda(v+u)=\lambda v + \lambda u && (\text{disztributivitÃ¡s a vektorok Ã¶sszeadÃ¡sÃ¡ra})
\end{aligned}
$$

</AxiomBox>

**PÃ©ldÃ¡k vektorterekre**

ğŸ‘¨â€ğŸ«: Probald meg belatni hogy az alabbi halmazok vektorteret alkotnak.

*   $\mathbb{R}^n$, $\mathbb{C}^n$
*   $C(\mathbb{R},\mathbb{R})$ (folytonos fÃ¼ggvÃ©nyek tere)
*   Sorozatok tere (mindenÃ¼tt definiÃ¡lt Ã¶sszeadÃ¡s Ã©s skalÃ¡rszorzÃ¡s){/* ez itt miez */}
*   $\{0\}$ (triviÃ¡lis vektortÃ©r)
{/* todo ezt itt meg nagyon szepiteni kene */}
## LineÃ¡ris kombinÃ¡ciÃ³

ğŸ‘¨â€ğŸ«: Mivel a vektorter zart az osszeadasra, igy az $I$ indexhalmazon
1. $\forall i\in I:\; u_i\in V$,
2. $\forall i\in I:\; \lambda_i\in K$,

akkor
$$
v=\sum_{i \in I}\lambda_i u_i \in V.
$$
Ekkor azt mondjuk, hogy $\sum_{i\in I}\lambda_i u_i$ az $(u_i)_{i\in I}$ vektorok valamely lineÃ¡ris kombinÃ¡ciÃ³ja.

## LineÃ¡ris fÃ¼ggetlensÃ©g

Az $(u_i)_{i\in I}$ vektorrendszer elemei lineÃ¡risan fÃ¼ggetlenek, ha
$$
\sum_{i\in I}\lambda_i u_i = 0 \quad\Longleftrightarrow\quad \forall i\in I:\; \lambda_i = 0.
$$
SzÃ³ban: az $(u_i)_{i\in I}$ vektorrendszer elemei akkor Ã©s csak akkor lineÃ¡risan fÃ¼ggetlenek, ha a nullvektort elÅ‘Ã¡llÃ­tÃ³ lineÃ¡ris kombinÃ¡ciÃ³ban szereplÅ‘ Ã¶sszes egyÃ¼tthatÃ³ nulla.

<div id="linear-independence-container" style={{display: 'flex', flexDirection: 'column', alignItems: 'center', margin: '2rem 0'}}></div>
<script is:inline src="/libraries/p5.min.js"></script>
<script is:inline src="/linear_independence_sim.js"></script>

**Feladatok**

1. VizsgÃ¡ljuk, hogy egyetlen vektor $v\in V$ lineÃ¡risan fÃ¼ggetlen-e.
2. TegyÃ¼k fel, hogy $V=\mathbb{R}^2$. VizsgÃ¡ljuk, hogy a kÃ¶vetkezÅ‘ kÃ©t vektor lineÃ¡risan fÃ¼ggetlen-e:
   $$
   a=(0,1),\qquad b=(1,1).
   $$

## BÃ¡zis, dimenzio

Egy $V$ vektortÃ©rben az $(u_i)_{i\in I}$ vektorrendszer bÃ¡zis, ha
1. $(u_i)_{i\in I}$ lineÃ¡risan fÃ¼ggetlen,
2. minden $x\in V$ elÅ‘Ã¡llÃ­thatÃ³ az $(u_i)_{i\in I}$ lineÃ¡ris kombinÃ¡ciÃ³jakÃ©nt, azaz $\operatorname{span}\{u_i:i\in I\}=V$.

**ÃllÃ­tÃ¡s**: Minden vektortÃ©rben van bÃ¡zis.
{/*todo na ezt en nem igy irtam, es kiegesziteni */}

ğŸ‘¨â€ğŸ«: Egy vektorter dimenzioja a vektorterben levo bazisok szamossaga. Tehat peldaul.: $ dim(\mathbb{R}^{3}) = 3 $

## Linearis alter, linearis burok

ğŸ‘¨â€ğŸ«: Vegyuk az ($\mathbb{R}^3$) teret. Errol mar belattuk, hogy vektorteret alkot. Vegyuk ehhez a szokasos, standard $ x, y, z $ koordinatazast. Most vegyunk azonak a vektoroknak a halmazat amelyek $ [a, b, 0] $ alakba irhatoak. Mi tortenik ha ket ilyen vektort osszeadunk?

ğŸ™‹â€â™‚ï¸: Hat tovabbra is az $ xy $ sikban maradnak.

ğŸ‘¨â€ğŸ«: Pontosan. Es ha egy ilyen vektort megszorzunk egy skalarral?

ğŸ™‹â€â™‚ï¸: Szinten az $ xy $ sikban marad a modositott vektor.

ğŸ‘¨â€ğŸ«: Ezek a vektorok mar eredetileg is egy vektorter elemei voltak. Igy mit mondhatunk el ezeknek az $ [a, b, 0] $ alaku vektorok halmazarol?

ğŸ™‹â€â™‚ï¸: Hat igazak rajuk a vektorter axiomai. Es valahogy igy nem tudnak "kimenni" az $ xy $ sikrol. Szoval azt gondolom hogy ok is egyfajta kisebb vektorteret alkotnak.

cNagyon jooo. Ezt linearis alternek nevezzuk. $ L \subseteq V $ linearis altere a $V$ vektorterunknek, ha:

$$
\begin{aligned}
1. \quad & a, b \in L \implies a + b \in L \\
2. \quad & a \in L, \lambda \in K \implies \lambda a \in L
\end{aligned}
$$

{/* todo ide kep az egyenesrol es arrol h subset */}

ğŸ™‹â€â™‚ï¸: Szoval a null vektor mindig bennevan a linaris alberben, es az egesz vektorter mindig egy linaris alter is egyben, ha jol ertem

ğŸ‘¨â€ğŸ«: Igen, igen, nagyon jÃ³ Ã©szrevÃ©telek. Haladjunk tovÃ¡bb a lineÃ¡ris burok fogalmÃ¡ra. Ha van egy $V$ vektorterÃ¼nk Ã©s abban egy $A = \{v_1, v_2, \dots, v_n\}$ vektorrendszerÃ¼nk, akkor $A$ lineÃ¡ris burka ($\langle A \rangle$):

$$
\langle A \rangle = \left\{ \sum_{i=1}^{n} \lambda_i v_i : \lambda_i \in \mathbb{K}, n \in \mathbb{N} \right\}
$$

ğŸ™‹â€â™‚ï¸: Ez a burok linaris burok dolog igazabol linearis alteret konstrual, nem?

ğŸ‘¨â€ğŸ«: Igen. Ha osszeadod ket linearis kombinaciojat a vektorrendeszernek akkor az meg mindig a vektrorrendszered linearis kombinacioja lesz. Ugyanez igaz a szorzasra is. Tehat valoban, a linaris burok elkeszitese egy olyan "gepezet" ami a vektorrendszerunkre illeszt egy linaris alteret. De meg az is igaz hogy a leheto legkisebb linaris alteret illeszti az eredeti vektorainkra. Ezt ertheted ugy, hogy ha van a 3D-s terben ket vektorod akkor azoknak a linaris burka egy sikot fog meghatarozni nem pedig az egesz 3D-s teret.






## SkalÃ¡rszorzatos vektorterek

ğŸ™‹â€â™‚ï¸: VÃ¡rjunk csak, a 3 dimenziÃ³s tÃ©rben tudtunk vektorokat szorozni pl.: skalÃ¡risan vagy vektoriÃ¡lisan. Ezt a tulajdonsÃ¡got nem Ã¡ltalÃ¡nosÃ­tottuk?

ğŸ‘¨â€ğŸ«: Ez egy nagyon Ã¼gyes Ã©szrevÃ©tel! (jÃ¡r Ã©rte egy csoki) A vektorterekre adott Ã¡ltalÃ¡nos definÃ­ciÃ³nk valÃ³ban nem foglalja magÃ¡ba a vektorok szorzÃ¡sÃ¡t. Azonban egyes vektorterekben lÃ©tezik skalÃ¡ris szorzÃ¡s ezeket a vektortereket -- nagyon meglepÅ‘ mÃ³don -- skalÃ¡rszorzatos vektortereknek nevezzÃ¼k. PÃ©ldÃ¡ul ahogy lÃ¡ttuk a sÃ­k ($\mathbb{R}^2$) vektorteret alkot (a valÃ³s szÃ¡mtest fÃ¶lÃ¶tt), Ã©s a sÃ­kon 2 vektornak lÃ©tezik skalÃ¡ris szorzata.

ğŸ™‹â€â™‚ï¸: Hmm... Es mi a helyzet a folytonos fÃ¼ggvÃ©nyekkel azok is vektorteret alkotnak, nem? Ott nem tudom csak Ãºgy Ã¶sszeszorozni a vektorok komponenseit mint egy ($\mathbb{R}^n$)-es vektortÃ©rben. Akkor itt nincs skalÃ¡ris szorzÃ¡s?

ğŸ‘¨â€ğŸ«: Igen igen, ez egy nehÃ©zsÃ©g. Ha emlÃ©kszel a kÃ¶zÃ©piskolÃ¡ban tanult vektorrÃ³l alkotott kÃ©p valami olyasmi volt, hogy egy sÃ­kon vagy egy tÃ©rben lakÃ³ nyilacska vagy egymÃ¡s alÃ¡ pakolt szÃ¡mok. Amikor bevezettÃ¼k a vektortereket valahogy megvizsgÃ¡ltuk, hogy milyen belsÅ‘ tulajdonsÃ¡gokkal bÃ­rnak a ezek a vektorok. Ezeket a tulajdonsÃ¡gokat megtartottuk Ã©s ezekbÅ‘l megalkottuk a vektortÃ©r axiÃ³mÃ¡it. Most valami hasonlÃ³t fogunk csinÃ¡lni a skalÃ¡rszorzÃ¡ssal is. Vajon milyen tulajdonsÃ¡gai vannak a sÃ­kon vett standard skalÃ¡rszorzÃ¡snak?

ğŸ™‹â€â™‚ï¸: Gondolkozzunk... VegyÃ¼nk kÃ©t vektort, mondjuk $a$-t Ã©s $b$-t. 1. Ha $a$ hosszÃ¡t 2-szeresÃ©re nÃ¶velem akkor a skalÃ¡rszorzat is kÃ©tszer akkora lesz. Ezt geometriailag lÃ¡thatjuk. 2. Ha veszÃ¼nk egy harmadik vektort, mondjuk $c$-t, akkor ha $a + b$-t skalÃ¡risan szorozzuk $c$-vel az igazÃ¡bÃ³l ugyan olyan mintha elÅ‘szÃ¶r $a$-t szoroztuk volna $c$-vel Ã©s aztÃ¡n ehhez hozzÃ¡adtuk volna $b$ Ã©s $c$ saklÃ¡rszorzatÃ¡t. Ezt pedig onnÃ©t tudhatjuk, hogy ha kibontjuk a skalÃ¡rszorzatot komponensekre akkor ott mÃ¡r a szorzÃ¡s disztributÃ­v a valÃ³s szÃ¡mokon Ã©s utÃ¡na Ã¡trendezzÃ¼k az Ã¶sszeget. 3. Hogyha $a$-t Ã¶nmagÃ¡val skalÃ¡rszorozzuk akkor biztos, hogy egy pozitÃ­v szÃ¡mot kapunk, feltÃ©ve persze, hogy $a$ nem nullvektor. Hmmm... nem tudom mi van mÃ©g. Ja igen talÃ¡n mÃ©g egy. 4. FelcserÃ©lhetjÃ¼k a szorzÃ¡s sorrendjÃ©t Ã©s ugyan azt az eredmÃ©nyt kapjuk. TehÃ¡t $a$ szor $b$ = $b$ szer $a$

ğŸ‘¨â€ğŸ«: Wooow, nagyon jo Ã¼gyesen megfigyelted ezeket a tulajdonsÃ¡gokat! Persze egy kis kiegÃ©szÃ­tÃ©sre azÃ©rt szÃ¼ksÃ©g lesz, ha a vektorterÃ¼nket esetleg komplex szÃ¡mtest felett akarjuk definiÃ¡lni, de alapvetÅ‘en elÃ©g hasonlÃ³ marad a szitu ahhoz amit mondtÃ¡l. (HasznÃ¡ljuk a $ \langle \cdot, \cdot \rangle $ jelÃ¶lÃ©st.)

{/* todo ide johetne kÃ©rdÃ©s */}

SkalÃ¡rszorzat feltÃ©tele egy vektortÃ©rben:

1. $ \langle a, b \rangle = \overline{\langle b, a \rangle} $
2. $ \langle \lambda a, b \rangle = \bar{\lambda} \langle a, b \rangle $
3. $ \langle a + b, c \rangle = \langle a, c \rangle + \langle b, c \rangle $
4. $ \langle a, a \rangle > 0 $ ha a nem a nullvektor
5. $ \langle a, a \rangle = 0 $ ha a a nullvektor

ğŸ™‹â€â™‚ï¸: OkÃ©, hogy segÃ­t ez nekÃ¼nk a folytonos fÃ¼ggvÃ©nyeken Ã©rtelmezni a skalÃ¡rszorzÃ¡st? NÃ©zhetnÃ©nk erre egy pÃ©ldÃ¡t?

ğŸ‘¨â€ğŸ«: Azt mÃ¡r korÃ¡bban belÃ¡ttuk, hogy a folytonos fÃ¼ggvÃ©nyek a $[0, 1]$ intervallumon vektorteret alkotnak. tekintsÃ¼k a kÃ¶vetkezÅ‘ skalÃ¡ris szorzÃ¡st:

$ \langle f, g \rangle = \int_{0}^{1}f(x)g(x) \, dx $

ha lecsekkolod a fent emlÃ­tett kritÃ©riumokat rÃ¡jÃ¶ssz, hogy ez egy valid skalÃ¡ris szorzÃ¡s ezen a vektortÃ©ren.
{/* todo ezt itt lehet levezethetnem */}

## Normak

ğŸ‘¨â€ğŸ«: Ahhogy a skalarszorzast is altalanositanunk kellett ha kicsit elborultabb vektorterekkel dolgoztunk, igy a vektorok hosszat sem olyan konnyu mar lemerjuk. Hasonloan itt is be fogunk vezetni egyes axiomakat. Es inkabb a norma szot fogjuk hasznalni a hossz helyett. Ha visszagondolsz a skalarszorzat axiomaira, milyen felteteleket kene szabjunk, hogy altalanosithassuk a vektor hosszat?

ğŸ™‹â€â™‚ï¸: Szerintem itt is hasznos lenne ha nem engednenk meg hogy egy vektor negativ hosszu legyen. Meg hogyha a vektort megszorozzuk 5-tel akkor a normaja is lehetne 5-szor akkora.

ğŸ‘¨â€ğŸ«: Jo otlet! Meg egy kicsit kiegeszitem es mar meg is van a norma definicioja.
$$
\begin{aligned}
\|\cdot\| : V \to \mathbb{R} \\
1. \quad & \|x\| \ge 0 \\
2. \quad & \|x\| = 0 \iff x = 0 \\
3. \quad & \|\lambda x\| = |\lambda| \|x\| \\
4. \quad & \|x + y\| \le \|x\| + \|y\|
\end{aligned}
$$

Szoval a norma egy olyan fuggveny ami a vektorterbol kepez a valos szamokba. Es valoban, a norma mindig nagyobb mint 0 kiveve ha magat a 0 vektort normaljuk. Abban is igazad volt, hogy ki kell tudjuk hozni a skalar szorzot. Itt annyi pontositast tettem hogy a skalar abszoluterteket kell tudjuk kiemelni. Ez azert kell mert lehet, hogy a  komplex kest folott van definialva a vektorterunk. Amit viszont elfelejtettel emliteni az a haromszogegyenlotlenseg. Ha van kedved leellenorizheted, hogy a sikon hasznalt standard norma kielegiti a normara adott felteteleinket. ( $ \|x\| = \sqrt{x_1^{2} + x_2^{2}} $ )

ğŸ™‹â€â™‚ï¸: Hmmm... A normaban es a skalarszorzasban latszolag eleg sok kozos tulajdonsag van. Nem tudjuk valahogy oket osszekotni?

ğŸ‘¨â€ğŸ«: Jo meglatas. Pont ezzel fogjuk folytatni. Ha van egy skalarszorzatos vektorterunk akkor abban a skalarszorzas normat indukal.:
$$
\|x\| = \sqrt{\langle x, x \rangle}
$$

{/* todo ez itt nincs befelyezve */}

<div id="p-norm-container" style={{display: 'flex', flexDirection: 'column', alignItems: 'center', margin: '2rem 0'}}></div>
<script is:inline src="/p_norm_sim.js"></script>

## Caucy-Schwarz-Bunyakowskij egyenlotlenseg es vektorok altal bezart szog

ğŸ‘¨â€ğŸ«: Vegyunk a megszokott sikon ket vektort. Itt mindenki szamara egyertelmu hogy mi a ket vektor altal bezart szog. Akar foghatunk egy szogmerot is es leolvashatjuk a szoget. Na de vegyuk most a folytonos fuggvenyek vektorteret. Itt mi a helyzet, hogy hatarozzuk meg ebben a vektorterben lako ket vektor altal bezart szoget?

ğŸ™‹â€â™‚ï¸: Ha jol emlekszem a szog valahogy kapcsolatban allt a skalarszorzassal. Ki tudnank esetleg azt hasznalni?

ğŸ‘¨â€ğŸ«: Nem is rossz otlet! Kicsit tavolabbrol fogok elindulni de vegul ide fogunk kilyukadni. Ha van egy skalarszorzatos vektorterunk akkor abban mindig fennall egy nagyon fontos egyenlotlenseg.:

$$
| \langle x, y \rangle | \leq \|x\| \|y\|
$$

(Itt $ \|x\| := \sqrt{\langle x, x \rangle} $ kesobb be fogjuk latni, hogy $ \|x\| $ a skalarszorzat altal indukalt normaja $ x $-nek. Most egyelore viszont csak egy jelolesbeli egyszerusites.) Ez egy tok hasznos egyenlotlenseg. Ezt fogjuk hasznalni a vektorok altal bezart szog definialasara is mellesleg. Lenyegileg annyit mont ki, hogy ha van ket vektorunk akkor azoknak a skalarszorzata biztos, hogy kisebb vagy egyenlo, mint ha a ket vektort onmagukkal skalarszorozzuk, es aztan a skalarszorzatokat osszeszorozzuk.

{/* todo ami ezalatt ki van kommentelve az nem teljesen igaz */}
{/* 
ğŸ™‹â€â™‚ï¸: Ahaa. Eeees akarmilyen normat hasznalhatok? Peldaul a p-normak kozul megvalaszthatom a p erteket 14-nek?

ğŸ‘¨â€ğŸ«: Nagyon jo kerdes! Itt fontos megemliteni, hogy mindig a skalarszorzas altal indukalt normat hasznaljuk az egyenlotlensegben. Kiprobalhatod peldaul a sikon az $ (1, 1), (2, 2) $ vektorokon a szokasos skalarszorzassal es a vegtelen normaval. Nem fog mukodni az egyenlotlenseg. Na de ha mar itt vagyunk lassuk is be gyorsan ezt az egyenlotlenseget! */}

<ProofBox title="C.S.B. bizonyitas">
$$
\begin{aligned}
& \|x - \lambda y\| \ge 0 \\
& (\text{ahol } \forall x, y \in V, \forall \lambda \in K, y \neq 0) \\
\\
& \text{A skalarszorzatot visszairva:} \\
& \langle x - \lambda y, x - \lambda y \rangle \ge 0 \\
\\
& \text{Kibontva:} \\
& \langle x, x \rangle - \langle x, \lambda y \rangle - \langle \lambda y, x \rangle + \langle \lambda y, \lambda y \rangle \ge 0 \\
& \|x\|^2 - \lambda \langle x, y \rangle - \bar{\lambda} \langle y, x \rangle + |\lambda|^2 \|y\|^2 \ge 0 \\
\\
& \text{Mivel minden } \lambda\text{-ra igaz az egyenlÅ‘tlensÃ©g,} \\
& \text{Ã­gy legyen: } \lambda = \frac{\langle y, x \rangle}{\|y\|^2} \\
\\
& \text{BehelyettesÃ­tve:} \\
& \|x\|^2 - \frac{\langle y, x \rangle \langle x, y \rangle}{\|y\|^2} - \frac{\overline{\langle y, x \rangle}\langle y, x \rangle}{\|y\|^2} + \frac{|\langle y, x \rangle|^2 \|y\|^2}{\|y\|^4} \ge 0 \\
\\
& \text{KihasznÃ¡ljuk a komplex szÃ¡m Ã©s konjugÃ¡ltjÃ¡ra} \\
& \text{vonatkozÃ³ Ã¶sszefÃ¼ggÃ©st: } (z \bar{z} = |z|^2) \\
& \|x\|^2 - \frac{|\langle y, x \rangle|^2}{\|y\|^2} - \frac{|\langle y, x \rangle|^2}{\|y\|^2} + \frac{|\langle y, x \rangle|^2}{\|y\|^2} \ge 0 \\
\\
& \text{Ã–sszevonÃ¡s utÃ¡n:} \\
& \|x\|^2 - \frac{|\langle y, x \rangle|^2}{\|y\|^2} \ge 0 \\
& \|x\|^2 \ge \frac{|\langle y, x \rangle|^2}{\|y\|^2} \\
& \|x\|^2 \|y\|^2 \ge |\langle x, y \rangle|^2 \\
\\
& \text{GyÃ¶kvonÃ¡s utÃ¡n:} \\
& |\langle x, y \rangle| \le \|x\| \|y\|
\end{aligned}
$$
</ProofBox>







ğŸ‘¨â€ğŸ«: Emlekszel meg, hogy a kozepsuliban hogy definialtak a skalarszorzatot?

ğŸ™‹â€â™‚ï¸: Igen. Ket vektor skalarszorzata a vektorok hosszanak szorzata, es ezt meg megszorozzuk a ket vektor altal bezart szok koszinuszaval. Szoval valami ilyesmi kepletet kaptunk:

$$
x \cdot y = |x||y|cos(\alpha)
$$









SPONGZABOBOS KEPEN MATRIXOK NEZEGETESE

EZ ITT TOK MAS LESZ MOST

## AsszociatÃ­v algebra

ğŸ‘¨â€ğŸ«: EmlÃ©kszel mÃ©g arra amikor definiÃ¡ltuk a skalÃ¡rszorzÃ¡st egy vektortÃ©ren? Eredetileg a vektortÃ©r elemeit csak Ã¶sszeadni tudtuk, meg skalÃ¡rral szorozni (jo persze volt inverz meg ilyesmik). Zavart, hogy nem tudtunk Ã¶sszeszorozni kÃ©t vektort. Ãgy bevezettÃ¼nk egy olyan fÃ¼ggvÃ©nyt ami megeszik kÃ©t vektort Ã©s kikÃ¶p egy skalÃ¡rt. Ez mÃ¡r egÃ©sz jÃ³! BÃ¡r azÃ©rt mÃ©g mindig zavar, hogy nem tudunk kÃ©t vektort Ã¶sszeszorozni Ãºgy, hogy egy harmadik vektort kapjunk.

ğŸ™‹â€â™‚ï¸: De vÃ¡rjunk az $n \times n $-es mÃ¡trixok vektorteret alkotnak, Ã©s mÃ¡trixokat tudunk Ã¶sszeszorozni. Akkor ha jÃ³l Ã©rtem akkor vannak vektorterek ahol mÃ¡r autÃ³matikusan mÅ±kÃ¶dik a vektorok szorzÃ¡sa.

ğŸ‘¨â€ğŸ«: Pontosan. Nagyon jÃ³ meglÃ¡tÃ¡s! Ha megfigyeljÃ¼k az nxn-es mÃ¡trixok szorzÃ¡sÃ¡ra vonatkozÃ³ jellemzÅ‘ket a kÃ¶vetkezÅ‘ket kapjuk: A, B, C mÃ¡trixok $ \lambda \mu $ skalÃ¡rok
1. $ A(BC) = (AB)C $
2. $ A(B + C) = AB + AC $
3. $ (A + B)C = AC + BC $
4. $ (\lambda A) (\mu B) = (\lambda \mu) (AB) $

NamÃ¡rmost nem csak a mÃ¡trixokra lehetnek igazak ezek a szabÃ¡lyok. Ha egy vektortÃ©r elemeire igazak a fÃ¶nti szabÃ¡lyok akkor azt mondhatjuk, hogy a vektortÃ©r elemei egy asszociatÃ­v algebrÃ¡t alkotnak. ÃltalÃ¡ban kis betÅ±vel Ã­rjuk a vektorokat, Ã­gy a szabÃ¡lyok egy asszociatÃ­v algebra lÃ©tezÃ©sÃ©hez:

1. $ a(bc) = (ab)c $
2. $ a(b + c) = ab + ac $
3. $ (a + b)c = ac + bc $
4. $ (\lambda a) (\mu b) = (\lambda \mu) (ab) $
(ha $\forall a, b, c \in V$ Ã©s $ \forall \lambda, \mu \in \mathbb{K}$ skalÃ¡rra igazak a szabÃ¡lyok)

<Question
  question="Az alÃ¡bbi hÃ¡rom kÃ¶zÃ¼l mi nem alkot asszociatÃ­v algebrÃ¡t?"
  options={[
    "Polinomok a standard polinom szorzÃ¡ssal",
    "R^3 ban lÃ©vÅ‘ vektorok vektoriÃ¡lis szorzÃ¡ssal",
    "f:R->R folytonos fÃ¼ggvÃ©nyek, a szorzÃ¡s a fÃ¼ggvÃ©nyÃ©rtÃ©kek normÃ¡l szorzÃ¡sa"
  ]}
  correctAnswerIndex={1}
/>

ğŸ‘¨â€ğŸ«: Ha visszatekintÃ¼nk a mÃ¡trixok szorzÃ¡sÃ¡ra egyes $n \times n $ mÃ¡trixoknak volt egy elÃ©g fontos tulajdonsÃ¡ga. EmlÃ©kszel mi volt ez?

ğŸ™‹â€â™‚ï¸:Hmmm... Ha egy mÃ¡trixnak nem zÃ©rus volt a determinÃ¡nsa akkor invertÃ¡lhatÃ³ volt, ha jÃ³l emlÃ©kszem.

ğŸ‘¨â€ğŸ«:Nagyon jÃ³Ã³. Ha visszaemlÃ©kezÃ¼nk $ A^{-1} $ az  $A$ mÃ¡trix inverze volt ha $ A^{-1}A = AA^{-1} = I $ Ahol $ I $ az $n \times n $-es
identitÃ¡smÃ¡trix volt.

Viszont ahhoz, hogy invertÃ¡ljunk kell az algebrÃ¡nkba egysÃ©gelem. Azokat az asszociatÃ­v algebrÃ¡kat amiben ilyen van azt egysÃ©gelemes asszociatÃ­v algebrÃ¡nak hÃ­vjuk (nagyon meglepÅ‘).
ÃltalÃ¡ban az egysÃ©gelemet $ e $-vel jelÃ¶ljÃ¼k. Az $A$ egysÃ©gelemes algebrÃ¡ra teljesÃ¼lnie kell, hogy: $ ae = ea = a : \forall a \in A $
Na mostmÃ¡r definiÃ¡lhatjuk az inverzet! $ a \in A $ invertÃ¡lhatÃ³, ha: $ \exists a^{-1} \in A : a^{-1}a = aa^{-1} = e $

VigyÃ¡zat az, hogy lÃ©tezik egysÃ©gelem az algebrÃ¡nkban nem jelenti azt, hogy feltÃ©tlen minden eleme az algebrÃ¡nknak invertÃ¡lhatÃ³! NÃ©zd pÃ©ldÃ¡ul a kÃ¶vetkezÅ‘ mÃ¡trixot:
$B =
\begin{bmatrix}
2 & 2\\
2 & 2
\end{bmatrix} $

### AsszociatÃ­v algebra spektruma

Egy egysÃ©gelemes asszociatÃ­v algebrÃ¡nak lÃ©tezik spektruma is. Az algebra egy $ a $ elemÃ©nek a spktruma azoknak a skalÃ¡roknak a halmaza amikre nem lÃ©tezik inverze $ a - \lambda e $-nak:

$$
sp(a) = \{ \lambda \in \mathbb{K} : \nexists (a - \lambda e)^{-1} \}
$$

Valahol mÃ¡r lÃ¡ttunk hasonlÃ³t. IsmerÅ‘s ez valahonnÃ©t?

ğŸ™‹â€â™‚ï¸:Sajnos nem.

ğŸ‘¨â€ğŸ«:Ha visszaemlÃ©kszÃ¼nk a sajÃ¡tÃ©rtÃ©k szÃ¡mÃ­tÃ¡sra, ott valami ilyesmi kÃ©pletÃ¼nk volt: $ \lambda $ sajÃ¡tÃ©rtÃ©ke $ A $-nak, ha $ det(A - \lambda I) = 0 $

ğŸ™‹â€â™‚ï¸:Aaa, mostmÃ¡r Ã©rtem. Ha nem lÃ©tezik $ (a - \lambda e) $-nek inverze az a mÃ¡trixok nyelvÃ©n azzal egyenÃ©rtÃ©kÅ±, hogy $ det(A - \lambda I) = 0 $ Mivel ha egy mÃ¡trixnak a determinÃ¡nsa $ 0 $ az azt jelenti, hogy a mÃ¡trix nem invertÃ¡lhatÃ³ (Ã©s vica verza).

ğŸ‘¨â€ğŸ«:Igen, a mÃ¡trixoknÃ¡l valÃ³ban a spektrum egyenÃ©rtÃ©kÅ± a sajÃ¡tÃ©rtÃ©kek halmazÃ¡val (vÃ©gtelen dimenziÃ³ban mÃ¡r nem csak a sajÃ¡tÃ©rtÃ©kekbÅ‘l Ã¡ll a spektrum, de ez most nem fontos).




## Jacobson-lemma:

ğŸ‘¨â€ğŸ«:Oooookes, most megnÃ©zÃ¼nk mengint egy kicsit absztraktabb Ã¡llÃ­tÃ¡st. IgÃ©rem lesz kicsit fÃ¶ldhÃ¶z ragadtabb kÃ¶vetkezmÃ©nye ami hasznunkra vÃ¡lhat.

Ãgy nagy vonalakban az Ã¡llÃ­tÃ¡s arrÃ³l szÃ³l, hogy ha van egy egysÃ©gelemes algebrÃ¡nk akkor aminek kÃ©t eleme a Ã©s b, akkor ab spektruma nem nagyon kÃ¼lÃ¶nbÃ¶zik ba spektrumÃ¡tÃ³l. Ez kicsit preciÃ­zebben.:

Van egy $ A $ egysÃ©gelemes ($ e $) algebrÃ¡nk. Ahol $ a, b \in A $. Ekkor:
$$
sp(ab) \cup \{0\} = sp(ba) \cup \{0\}
$$

NajÃ³ prÃ³bÃ¡ljuk meg belÃ¡tni ezt az Ã¡llÃ­tÃ¡st.



<ProofBox title="BizonyÃ­tÃ¡s: Jacobson-lemma">

$$
\begin{aligned}
& \text{Legyen } \lambda \notin \sigma(ab), \quad \lambda \in \mathbb{K}, \lambda \neq 0 \\
& \text{Legyen } c := (ab - \lambda e)^{-1} \\
& \text{TFH. } (ba - \lambda e)^{-1} = \alpha e + \beta bca \quad (\text{where } \alpha, \beta \in \mathbb{K}) \\
\\
& \text{Ahhoz hogy a feltÃ©tel teljesÃ¼ljÃ¶n: } (ba - \lambda e)(\alpha e + \beta bca) = e \\
\\
& \text{Kibontva:} \\
& \alpha ba + \beta babca - \lambda \alpha e - \lambda \beta bca = e \\
\\
& \text{VÃ¡lasszuk meg } \alpha \text{ Ã©rtÃ©kÃ©t:} \\
& -\lambda \alpha = 1 \implies \alpha = -\frac{1}{\lambda} \\
\\
& e\text{-vel egyszerÅ±sÃ­tve:} \\
& \alpha ba + \beta babca - \lambda \beta bca = 0 \\
& b (\alpha e + \beta abc - \beta \lambda c) a = 0 \\
& b \left( \alpha e + \beta (ab - \lambda e)c \right) a = 0 \\
\\
& \text{Mivel } (ab - \lambda e)c = e: \\
& b (\alpha e + \beta e) a = 0 \\
\\
& \text{legyen:} \beta = \frac{1}{\lambda}
\\
& b (0) a = 0 \\
& 0 = 0 \\
& \text{Ezzel az Ã¡llÃ­tÃ¡st belÃ¡ttuk az egyik irÃ¡nyba.}\\
\\
& \text{MÃ¡sik irÃ¡ny feltÃ©tele: } (\alpha e + \beta bca)(ba - \lambda e) = e \\
\\
& \text{Kibontva:} \\
& \alpha ba - \lambda \alpha e + \beta bcaba - \beta \lambda bca = e \\
\\
& a\text{ Ã©rtÃ©kÃ©t megvÃ¡lasztva:} \\
& -\lambda \alpha = 1 \implies \alpha = -\frac{1}{\lambda} \\
\\
& \text{EgyszerÅ±sÃ­tve:} \\
& \alpha ba + \beta bcaba - \beta \lambda bca = 0 \\
& b (\alpha e + \beta cab - \beta \lambda c) a = 0 \\
& b \left( \alpha e + \beta c(ab - \lambda e) \right) a = 0 \\
\\
& \text{Mivel:} \\
& c = (ab - \lambda e)^{-1}, \text{ we have } c(ab - \lambda e) = e: \\
& b (\alpha e + \beta e) a = 0 \\
\\
& \text{legyen:}\beta = \frac{1}{\lambda}\\
& b (0) a = 0 \\
& \text{Ezzel az Ã¡llÃ­tÃ¡st belÃ¡ttuk a mÃ¡sik irÃ¡nyba is.}\\
\end{aligned}
$$

</ProofBox>
{/* todo itt azert csinald meg h szep legyen es a vegese kell meg egy kis magyarazat */}


ğŸ‘¨â€ğŸ«: Ez a tÃ©tel Ã©s a hozzÃ¡ tartozÃ³ levezetÃ©s talÃ¡n kicsit absztraktnak tÅ±nhet, de van ennek a tÃ©telnek egy hasznos kÃ¶vetkezmÃ©nye. Igaz-e az hogy ha van kÃ©t $ n \times n $-es mÃ¡trixunk: $ A, B $ akkor: $AB = BA$ ?

<Question
  question="Mi a vÃ¡lasz a fÃ¶nti kÃ©rdÃ©sre?"
  options={[
    "Igen mindig",
    "Nem soha",
    "ÃltalÃ¡ban nem (lehet, hogy spec. esetben igen)"
  ]}
  correctAnswerIndex={2}
/>

ğŸ‘¨â€ğŸ«: Pontosan. A mÃ¡trixszorzÃ¡s nem feltÃ©tlen kommutatÃ­v. A Jacobson-lemma miatt viszont belÃ¡thatjuk, hogy $ sp(AB) = sp(BA) $ ha $ A, B \in n \times n $-es mÃ¡trix. Ez elÃ©g menÅ‘Å‘Å‘. HabÃ¡r A Ã©s B szorzata nem feltÃ©tlen kommutatÃ­v, a spektrumuk azonos. TehÃ¡t a sajÃ¡tÃ©rtÃ©keik megegyeznek.
LÃ¡ssuk ezt be gyorsan:

<ProofBox title="BizonyÃ­tÃ¡s: sp(AB) = sp(BA)">

$$
\begin{aligned}
& \text{Legyen } A, B \in \mathbb{R}^{n \times n} \text{ mÃ¡trix.} \\
& \text{Legyen } \lambda \in sp(AB). \\
\\
& 1. \text{ Ha } \lambda \neq 0: \\
& \quad \text{A Jacobson-lemma miatt: } \lambda \in sp(BA). \\
\\
& 2. \text{ Ha } \lambda = 0: \\
& \quad \text{Azt korÃ¡bbrÃ³l tudjuk, hogy: } \det(AB) = \prod_{i=1}^n \lambda_i \\
& \quad \text{TehÃ¡t ha lÃ©tezik egy } \lambda \text{ ami nulla, akkor: } \det(AB) = 0. \\
& \quad \text{De azt is tudjuk, hogy: } \det(AB) = \det(A)\det(B) = \det(BA). \\
& \quad \text{TehÃ¡t: } \det(BA) = 0 \implies \lambda \in sp(BA).
\end{aligned}
$$
</ProofBox>
















{/* OTLETEK */}
{/* todo ilyet majd csinalhatnek: https://ximera.osu.edu/la/LinearAlgebra/MAT-M-0023/main */}